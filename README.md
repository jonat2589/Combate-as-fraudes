# Combate-as-fraudes

# Projeto: DetecÃ§Ã£o de Fraudes em TransaÃ§Ãµes Financeiras

## ğŸš€ VisÃ£o Geral

Este projeto visa desenvolver um modelo de Machine Learning capaz de identificar transaÃ§Ãµes financeiras fraudulentas utilizando um dataset sintÃ©tico que simula dados reais de transaÃ§Ãµes com cartÃ£o de crÃ©dito. O trabalho aborda desafios comuns em problemas de detecÃ§Ã£o de fraude, como o desbalanceamento de classes e a necessidade de otimizar mÃ©tricas especÃ­ficas como Recall e Precision.

## ğŸ¯ Objetivo

O principal objetivo Ã© construir um modelo preditivo que minimize as perdas financeiras causadas por fraudes (maximizando o Recall) sem gerar um volume excessivo de falsos alertas (controlando os Falsos Positivos), garantindo a aplicabilidade em um ambiente de produÃ§Ã£o.

## ğŸ“Š Dataset

O dataset utilizado contÃ©m transaÃ§Ãµes anonimizadas, onde as features `V1` a `V28` sÃ£o os principais componentes obtidos via PCA. AlÃ©m disso, as colunas `Time` (tempo decorrido desde a primeira transaÃ§Ã£o) e `Amount` (valor da transaÃ§Ã£o) sÃ£o fornecidas. A variÃ¡vel alvo Ã© `Class` (0 para legÃ­tima, 1 para fraude).

## ğŸ”‘ Principais Descobertas e Etapas

1.  **AnÃ¡lise ExploratÃ³ria de Dados (EDA):**
    * IdentificaÃ§Ã£o de **desbalanceamento extremo de classes** (`Class=1` representa apenas 0.17% das transaÃ§Ãµes).
    * AnÃ¡lise da variÃ¡vel `Time` e criaÃ§Ã£o da feature `Hour`, revelando concentraÃ§Ã£o de fraudes nas **horas da madrugada (1h-4h)**.
    * AnÃ¡lise da distribuiÃ§Ã£o de `Amount`, destacando que o **maior impacto financeiro das fraudes** estÃ¡ em transaÃ§Ãµes de alto valor, apesar da maioria das fraudes ser de baixo valor.
    * UtilizaÃ§Ã£o de **KDE plots** e anÃ¡lise de correlaÃ§Ã£o para identificar variÃ¡veis `V` com alto poder discriminatÃ³rio (e.g., V11, V12, V14, V17).

2.  **PrÃ©-processamento e Balanceamento de Classes:**
    * DivisÃ£o estratificada dos dados em treino e teste (`train_test_split`).
    * AplicaÃ§Ã£o de **SMOTE** (Synthetic Minority Over-sampling Technique) no conjunto de treino para balancear a classe minoritÃ¡ria, crucial para o aprendizado do modelo.

3.  **Modelagem e AvaliaÃ§Ã£o de Modelos:**
    * ComparaÃ§Ã£o de diversos algoritmos (RegressÃ£o LogÃ­stica, Random Forest, XGBoost).
    * O **XGBoost**, treinado com dados balanceados por SMOTE, foi o modelo escolhido por oferecer o melhor equilÃ­brio entre Recall e Precision.
    * **Resultados Finais do Modelo XGBoost (Otimizado):**
        ```
        Matriz de ConfusÃ£o:
        [[56794    70]
         [   14    84]]

        Classification Report:
                      precision    recall  f1-score   support

                   0       1.00      1.00      1.00     56864
                   1       0.55      0.86      0.67        98

            accuracy                           1.00     56962
           macro avg       0.77      0.93      0.83     56962
        weighted avg       1.00      1.00      1.00     56962

        AUC-ROC: 0.9784227386790394
        ```
    * **OtimizaÃ§Ã£o de HiperparÃ¢metros:** Foi realizada uma busca com `RandomizedSearchCV` para otimizar os hiperparÃ¢metros do XGBoost. Embora a otimizaÃ§Ã£o nÃ£o tenha resultado em ganhos substanciais de performance (o modelo jÃ¡ era robusto), ela validou a escolha dos parÃ¢metros prÃ³ximos aos padrÃµes.

4.  **AnÃ¡lise de Erros e Limiar de DecisÃ£o:**
    * A **curva Precision-Recall vs. Threshold** foi plotada para visualizar o trade-off entre PrecisÃ£o e Recall em diferentes limiares.
    * AnÃ¡lise dos **14 Falsos Negativos** (fraudes nÃ£o detectadas) e **70 Falsos Positivos** (alertas errados), revelando que transaÃ§Ãµes de baixo valor e a ausÃªncia de padrÃµes temporais muito especÃ­ficos podem ser pontos de dificuldade para o modelo.

## ğŸ›  Tecnologias Utilizadas

* `Python`
* `Pandas`
* `NumPy`
* `Matplotlib`
* `Seaborn`
* `Scikit-learn`
* `XGBoost`
* `Imbalanced-learn` (para SMOTE)

## ğŸš€ Como Executar o Projeto

1.  Clone este repositÃ³rio:
    ```bash
    git clone [https://github.com/](https://github.com/)[Seu-Usuario]/[Nome-do-Seu-Repositorio].git
    ```
2.  Navegue atÃ© o diretÃ³rio do projeto:
    ```bash
    cd [Nome-do-Seu-Repositorio]
    ```
3.  Crie e ative um ambiente virtual (recomendado):
    ```bash
    python -m venv venv
    source venv/bin/activate  # Linux/macOS
    .\venv\Scripts\activate   # Windows
    ```
4.  Instale as dependÃªncias:
    ```bash
    pip install -r requirements.txt
    ```
    (VocÃª precisarÃ¡ criar um arquivo `requirements.txt` com `pip freeze > requirements.txt` no seu ambiente com as bibliotecas instaladas)
5.  Abra e execute o notebook Jupyter:
    ```bash
    jupyter notebook
    ```
    O notebook principal Ã© `[Nome-do-Seu-Notebook.ipynb]`.

## ğŸ¤ ContribuiÃ§Ãµes

Sinta-se Ã  vontade para abrir issues ou pull requests se tiver sugestÃµes ou melhorias!

## ğŸ“§ Contato

JONATHAN CARVALHO
https://www.linkedin.com/in/jonathan-datascience/
